# Data cache pattern

## Usecase
- 동일하고 반복된 데이터에 대한 예측 요청이 있는 경우.
- 캐시 키로 데이터를 식별할 수 있는 경우.
- 데이터 검색 및 처리 속도를 높이고 싶은 경우.


## Architecture
Data cache pattern은 입력 데이터를 캐시합니다. 입력 데이터가 데이터베이스, 저장소 또는 디스크에 저장되어 있으면 데이터 수집 오버헤드를 줄일 수 있습니다. 

<br>

캐시할 데이터의 양은 비용과 사이즈의 균형에 따라 고려해야 할 수도 있습니다. 캐시 공간의 단가는 스토리지 또는 데이터베이스보다 크기가 작을수록 더 비싼 경향이 있으므로 캐시 삭제를 위한 정책을 계획하는 것을 추천합니다.

<br>

예측 결과가 시간에 따라 변경되면 오래된 예측으로 응답하지 않도록 이전 캐시를 지워야 합니다. 서비스 부하가 높아서 캐시 크기가 급격히 증가하는 경우 캐시 삭제 정책을 구체적으로 계획하는 것이 중요합니다. 대부분 캐시는 시간이 경과하거나 키 요청 빈도에 따라 지워집니다.

<br>

이 패턴에 대한 두 개의 아키텍처가 있습니다.

1. 입력 데이터를 캐시합니다. 이 경우 서비스는 데이터 웨어하우스에 입력 데이터를 요청하고 병렬로 캐시하며 캐시가 존재하면 예측 요청을 진행합니다. 캐시가 존재하지 않으면 데이터를 캐시에 추가하고 예측을 요청합니다. 전처리의 부하를 줄이기 위해 전처리 후 데이터를 캐시할 수 있습니다.

<br>

2. 요청하기 전에 전처리 또는 캐시합니다. 이런 경우 예측 요청 전에 서비스에서 첫 데이터 생성과 함께 데이터를 캐시합니다. 데이터에 대한 예측 요청을 받으면 캐시에서 예측을 검색합니다. 대기 시간을 개선하기 위해 캐시 속도를 높이려는 경우 이 방법이 선택하는 것이 좋습니다.


## Diagram
### Input data cache
![diagram1](diagram1.png)

### Prepare data cache
![diagram2](diagram2.png)


## Pros
- 요청을 예측 서버로 오프로드하고 성능을 향상시킵니다.
- 빠른 응답이 가능합니다.

## Cons
- 캐시 서버 비용이 부과됩니다.
- 캐시 삭제 정책이 필요합니다.

## Needs consideration
- 입력 데이터는 키로 식별할 수 있어야 합니다.
- 속도, 비용, 볼륨 간의 균형을 고려해야 합니다.
- 캐시 삭제 정책이 필요합니다.
- 데이터 캐시 정책이 필요합니다.

## Sample
https://github.com/shibuiwilliam/ml-system-in-actions/tree/main/chapter4_serving_patterns/data_cache_pattern
