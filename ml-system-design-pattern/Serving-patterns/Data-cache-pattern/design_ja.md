# Data cache pattern

## Usecase
- 同一データの推論リクエストが発生するワークフローの場合
- 同じデータを繰り返し入力データとする場合
- キャッシュのキーで検索可能な入力データの場合
- データ処理を高速にしたい場合

## Architecture
データ・キャッシュ・パターンは入力データをキャッシュするアーキテクチャです。入力データがデータベースやストレージにある場合、データをキャッシュしておくことでデータアクセスのオーバーヘッドを削減することが可能になります。<br>
キャッシュするデータ量はキャッシュのコストや容量とトレードオフになります。多くのキャッシュはストレージ等よりもコストが高く、容量が小さい傾向にあるので、コスト・オーバー、容量オーバーを避けるためにキャッシュクリアの方針が必要です。<br>
使用するデータが時間経過で変化するシステムの場合、定期的にキャッシュクリアして古いキャッシュを削除する必要があります。高アクセスのシステムでキャッシュ容量が増大する場合、どのタイミングでどのキャッシュを削除するか、検討する必要があります。一般的にキャッシュクリアは時間経過やリクエスト頻度に応じて実行します。<br>
このパターンは大きく2種類のアーキテクチャを考えることができます。<br>
1つ目は入力データをキャッシュするパターンです。この場合、入力データの取得をDWHとキャッシュへ並列で実施し、キャッシュ・ヒットした場合はDWHへのアクセスを中止して後続の推論へ移行します。キャッシュ・ヒットしない場合は推論しつつ、取得したデータをキャッシュに保存します。同様の発想で入力データを前処理後にキャッシュするパターンも可能です。この場合、最初のデータは前処理してキャッシュに保存しますが、以降は同じ入力データであれば前処理せずにキャッシュから取得することが可能です。このパターンは前処理のオーバーヘッドを減らしたい場合に有効です。<br>
2つ目のパターンはリクエストが来る前に前処理を済ませておくものです。データがDWHに投入された際にDWH等と連携して事前にデータ取得、前処理、キャッシュします。当該データを使うリクエストが入力された場合、キャッシュから前処理済みのデータを取得して推論に送ります。キャッシュ率を増強し、可能な限りキャッシュから推論することで速度を向上したい場合に有効なアーキテクチャになります。

## Diagram
### Input data cache
![diagram1](diagram1.png)

### Prepare data cache
![diagram2](diagram2.png)


## Pros
- データ取得や前処理のオーバーヘッドを削減することができる。
- 高速に推論を開始することが可能。

## Cons
- キャッシュ・サーバのコストが発生。
- キャッシュクリアの方針が必要。

## Needs consideration
- メリットとキャッシュのコスト、容量とのトレードオフ。
- キャッシュクリアのタイミング。
- データをキャッシュするパターンの選定。


## Sample
https://github.com/shibuiwilliam/ml-system-in-actions/tree/main/chapter4_serving_patterns/data_cache_pattern
